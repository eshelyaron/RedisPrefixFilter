#+TITLE: Extending Redis with the Prefix Filter
#+OPTIONS: toc:nil num:nil ^:{}
#+AUTHOR: Yael Barash, Hadar Tal, Eshel Yaron
#+bibliography: workshop.bib
#+STARTUP: inlineimages indent contents
#+LATEX_HEADER: \usepackage{natbib}
#+LATEX_HEADER: \newtheorem{invariant}{Invariant}[section]

* Introduction

This report presents our work on implementing a Redis module that
provides an interface to the /Prefix Filter/ data structure.

The first section includes background about the prefix filter and
Redis in general.  The second section describes our implementation and
explore future directions for development.  In the third section we
evaluate our implementation compared to the standard Bloom Filter and
Cuckoo Filter Redis modules.  The fourth and final section concludes
our work and experiences.

* Background: Redis and the Prefix Filter

** Prefix Filter
*** PF Theory

In \cite{even2022prefix}, the authors present the Prefix Filter, an
incremental filter that aims to be near optimal in its space
requirements, and provide fast queries and insertions, in comparison
to state-of-the-art filters.  Quoting \cite{even2022prefix}:

#+begin_quote
The prefix filter shares the common high-level structure of mod- ern
dynamic filters (hence, its space efficiency) but it exploits the lack
of deletion support to simultaneously obtain fast queries and
insertions... [It] uses a novel solution to the collision resolution
problem, in which typically only a single cache line is accessed per
filter operation.
#+end_quote

The prefix filter is a two-level structure, with each level storing
/key fingerprints/, which are short hashes of the keys stored in the
filter.  The first level is called the /bin table/, it is an array of
compact dictionaries that facilitate constant time operations.  These
dictionaries are called /pocket dictionaries/.  The pocket dictionaries
are a space-efficient representation of a bounded-size set, which uses
the Elias-Fano encoding. Due to the bounded size of the PDs, not all
key fingerprints reside in the bin array.  The second level is called
the /spare/. It holds fingerprints of keys that were evicted from the
bin array.  The spare can implemented with any incremental filter.

The essence of the prefix key is the policy it employs to choose which
fingerprints to forward to the spare.  The policy maintains an
invariant called the /Prefix Invariant/:

\begin{invariant}[Prefix Invariant]
Each bin $i$ contains a prefix of the sorted list of key fingerprints
of keys that were inserted into the prefix filter and whose dedicated
bin is $i$.
\end{invariant}

*** PF Implementation

The original implementation of the prefix filter written in C++, and
it is notably intended to be used for benchmarking different filters.
Thus the original implementation defines a generic filter API via a
C++ generic struct called =FilterAPI=, which is instantiated with
different underlying filter implementations, one of which is the
prefix filter.

#+begin_src c++
  template<typename Table> struct FilterAPI {};
#+end_src

Instances of =FilterAPI= implement a standard set of operations. The
most important methods for our discussion are:

#+begin_src c++
  // create a new filter
  static Table ConstructFromAddCount(size_t add_count);
  // add to the filter
  static void Add(uint64_t key, Table *table);
  // check if a key is in the filter
  static bool Contain(uint64_t key, const Table *table);
  // remove a key from the filter
  static void Remove(uint64_t key, Table *table);
  // space consumption
  static size_t get_byte_size(const Table *table);
  // capacity
  static size_t get_cap(const Table *table);
#+end_src

The prefix filter itself is implemented as a generic class, which can
be instantiated with different implementations for the spare table
used by the prefix table to store fingerprints that were evicted from
the bin array.

#+begin_src c++
  template<typename Table> class Prefix_Filter {
    ...
    public:
    Prefix_Filter(size_t max_items, const float loads[2]) {...}
    ...
  }
#+end_src

The pocket dictionaries are implemented as 256 bit wide integers
(=__m256i=), which are manipulated directly using Intel AVX512 vector
instructions.  Accordingly, the entire bin array is implemented as a
consecutive array of pocket dictionaries.

** Redis

Redis is an open source, in-memory data structure store used as a
database, cache, message broker, and streaming engine. Redis provides
data structures such as strings, hashes, lists, sets, sorted sets,
bitmaps, etc. Redis has built-in replication, Lua scripting, LRU
eviction, transactions, and different levels of on-disk persistence,
and provides high availability[fn:1].  Redis is one of the
most popular technologies and became a synonym for an In-Memory
database. Furthermore, it repeatedly occures in the Stack Overflow’s
annual developer survey under "most loved databases" category[fn:2]..

*** The Redis modules interface

Redis modules make it possible to extend Redis functionality using
external modules, rapidly implementing new Redis commands with
features similar to what can be done inside the core itself.  The full
API that we used can be found in the official Redis documentation, and
among other things contains loading module, creating commands and
working with Redis module data objects[fn:3].

[fn:1] https://redis.io/docs/about/
[fn:2] https://redis.com/blog/redis-is-the-most-loved-database-for-the-4th-year-in-a-row/
[fn:3] https://redis.io/docs/reference/modules/

* Challenges and solutions

** Developing on a remote host

Due to the fact that the prefix filter only runs and compiles on a
Linux hosts with an Intel processor with the AVX512 CPU vector
extension, the vast majority of the research and development work in
this project had to be carried out on a remote server that has this
extension.  This was challenging as we had to adapt our existing
development setups to achieve an efficient workflow.  To minimize the
cost of adapting to working on a remote development host, we leveraged
GNU Emacs with TRAMP[fn:4].
which allowed us to edit, compile and execute remote files seamlessly
while retaining the exact same setup and workflow we use for local
development.

[fn:4] https://www.gnu.org/software/tramp/

** Preparing the prefix filter for embedding in a shared object

Unlike the original prefix filter implementation which built the
prefix filter as part of a standalone executable written solely in
C++, our requirement was to embed the prefix filter implementation in
a shared object that implements the Redis module ABI.  To do that we
wrote a Makefile that leverages =g++= to build a shared library from the
all of the C++ source files of the prefix filter along with our
=module.c= source file which implements the Redis module API.

** Design

In high-level, the project is constructed from the following components:
- An implementation of the Prefix Filter data structure, adapted from
  \cite{even2022prefix}.
- A Redis module (shared library) exposing the Prefix Filter
  operations as Redis commands under the such as =PF.ADD=.
- A framework for running benchmarks against Redis filter modules.
- Scripts for instrumenting the Redis server.

Our Redis module is implemented in the C source file =module.c=, which
includes a header file called =redismodule.h= which defines the Redis
module API and ABI.  =module.c= further includes the header file
=wrappers.hpp= from our adapted Prefix Filter implementation, which
defines a generic API for filters in the C++ language.

In essence, =module.c= is tasked with implementing a bridge, or an
adapter, between the two interfaces.

*** Redis module initialization

As dictated by the Redis module API
[fn:5], our Redis module defines a
symbol =RedisModule_OnLoad=, implemented by a C function of the same
name in =module.c=.  The =OnLoad= function is invoked by the Redis runtime
upon loading a dynamic module, and its role is to initialize the
module and register any provided commands for later use.

The Redis module API provide the =RedisModule_Init= function for
initializing dynamic modules as part of their =OnLoad= routines.  Such
is the case also in our =OnLoad= implementation, which invokes
=RedisModule_Init= as its first step and registers through it the
command namespace =PF= for Prefix Filter commands.

Next, our =OnLoad= routine leverages the =RedisModule_CreateCommand=
function from the Redis module API to register a sequence of commands
for working with the underlying Prefix Filter through the Redis
interface.

[fn:5] https://redis.io/docs/reference/modules/
*** Provided Redis Commands

**** =PF.RESERVE=

The =PF.RESERVE= command creates an empty Prefix Filter.  The command
takes two arguments, a =name= argument and a =capacity= argument.  The
=name= argument is a string that can later be used to refer to the
created filter, and the =capacity= argument is an integer used to set
its maximum capacity.

**** =PF.ADD=

The =PF.ADD= command adds an element to a Prefix Filter.  The command
takes two arguments, a =name= argument and an =item= argument.  The =name=
argument specifies which Prefix Filter to add to, and should match the
name given to that filter upon creation with =PF.RESERVE=.  The =item=
argument is a string to be added as an element to the filter.

**** =PF.EXISTS=

The =PF.EXISTS= command checks whether a given Prefix Filter contains a
specific element.  The command takes two arguments, a =name= argument
and an =item= argument.  The =name= argument specifies which Prefix Filter
to check for the element, and the =item= argument is the element to test
for existence in the table.  As is generally the case for filters,
this command may yield false positive results, meaning it may succeed
although the given element had never been inserted into the table.

**** =PF.MADD=

The =PF.MADD= command is an enhanced version of the =PF.ADD= command which
allows for specifying any number of elements to add to the given
Prefix Filter.  The first argument to =PF.MADD= is the name of the
Prefix Filter to add elements to, and the rest of the arguments are
treated as items to add to the filter.  The command returns an array
of integers, one for each input element.  The returned array contains
=1= in each index =i= such that that =i='th input element was newly added to
the filter, and =0= in the rest.  To facilitate efficient insertion of
multiple keys at once, we annotate each key with its original position
in the input array and then sort the resulting array of annotated keys
according to the order of the bins to which the keys may be inserted.
Then insertion follows the sorted order of the annotated keys, so
insertions to adjacent bins takes place in consecutive steps, which
maximizes memory locality for the entire process.

**** =PF.MEXISTS=

The =PF.MEXISTS=, similarly to =PF.MADD=, is an enhanced version of the
=PF.EXISTS= command which allows for specifying any number of elements
to to the given Prefix Filter.  The first argument to =PF.MADD= is the
name of the Prefix Filter to add elements to, and the rest of the
arguments are treated as items to add to the filter.  The command
returns an array of integers, which contains =1= in each index =i= such
that that =i='th input element exists in the filter, and =0= in the rest.

**** =PF.INFO=

The =PF.INFO= command takes a single argument, the name of an existing
Prefix Filter table and returns information about the status of the
table.

#+begin_src
127.0.0.1:6379> pf.reserve my_table 1024
OK
127.0.0.1:6379> pf.info my_table
1) Capacity
2) (integer) 1024
3) Filled
4) (integer) 0
5) Size
6) (integer) 1568
#+end_src

** Future directions

*** Faster sorting for multi commands

It may be possible to improve the performance of the multi commands
(=PF.MADD= and =PF.MEXITS=) by leveraging a different sorting algorithm
than the currently used generic quicksort implementation.  In the
course of working on this project we have examined two main
alternatives:

1. Radix sort - we experimented with replacing the current quicksort
   with an implementation of radix sort.  On paper, radix sort is has
   better asymptotic time complexity compared to the comparison based
   quicksort.  Since we are need to reply with an array of results
   that corresponds to the order of the input array for multicommands,
   we must use the stable variant of radix sort.  Unfortunately the
   stable variant of radix sort does not sort the input in place and
   in general has a high cost in terms of memory locality.  For this
   reason we didn't find it preferable to the current implementation
   in our use case.

2. =Highway= based quicksort - we considered using the =Highway= library
   from Google[fn:6], a C++ library that provides portable SIMD/vector
   intrinsics, but decided against it because we found that
   integrating the entire library into our Redis module just for its
   quicksort implementation was not warranted, seeing as it would have
   also required non-trivial changes to our existing code to use the
   =Highway= API.

[fn:6] https://github.com/google/highway/

*** Presisting the prefix filter

One interesting part of the Redis module API that our current
implementation does not cover are the Redis Database save and /load
methods/.  The RDB save and load methods are C callback functions that
a Redis module provides for Redis to call when creating a persitent
snapshot of the current state and loading a snapshot from disk,
respectively.  These callbacks get a special IO handle and can use the
=RedisModule_Save*= and =RedisModule_Load*= interface functions which
allow for storing or retrieving values from the IO handle.  The only
values supported directly by this API are numeric values up to 64 bit
wide and strings of arbitrary size, hence the pocket dictionaries of
the prefix table will could be persisted either as four consecutive 64
bit integers, or as 32 byte long strings.  The entire bin array may
also be persisted as on large string buffer.  In either case, care
should be taken if persisted prefix tables are to be shared between
hosts with different endianness.

* Evaluation

** Benchmarks introduction

A Benchmark in Performance Testing is a metric or a point of reference
against which software products or services can be compared to assess
the quality measures. In other words, Benchmark means a set standard
that helps to determine the quality of a software product or a
service. We can benchmark a software product or service to assess its
quality.

We would like to compare the performance of the filters to determine
if there is any improvment by using the implemented data structure –
prefix filter. Filter data structures are used to test whether an
element is a member of a set. Particullary in redis, In-Memory filters
let us unswer that question in a near-realtime duration, so while
trying to compare the filters we should think about the filters's
latency while adding and querying data. We created performence tests
which measure the duration of the multi-add and multi-exists commands
under different amount of items in the command and increasing amount
of concurrent requests.

** Benchmarks implementation

While creating the benchmarks, we decided to use the Golang programing
language. Golang is expressive, clean, and efficient. Its concurrency
mechanisms make it easy to write programs that get the most out of
multicore and networked machines. We also had previous experience with
creating a Redis client in Go that is able to perform non-standard
Redis commands by using Lua scripts.

We have created a generic test function which receive -
- N - number of iterations
- M - number of parallel tests
- F - function to be tested
and returns the average durtion of N iterations, each contains M concurrent callings to F.

The benchmark folder includes -
- redis - a Redis client which is able to perform non-standard Redis commands.
- scripts- Lua scripts which Redis can execute.
- utils - random strings generator and the generic test function.
- visualisation - a python program for visualizing the results.
- correctnessTests.go - validate the behavior of the implemented commands.
- loadTests.go - perform the benchmarks.

** Results

In every benchmark, we set N (number of iterations) to 50.

*** Benchmark A
#+NAME:   fig:bench1
[[./testExistsPerNumberOfParalleledTests.png]]

*** Benchmark B
#+NAME:   fig:bench2
[[./testMAddPerNumberOfItems.png]]
- In every MADD test there was just one call.

*** Benchmark C
#+NAME:   fig:bench3
[[./testMAddPerNumberOfParalleledTests.png]]
- In every MADD command 10 records were added.

*** Benchmark D
#+NAME:   fig:bench4
[[./testMExistsPerNumberOfItems.png]]
- In every MExists test there was just one call.

*** Benchmark E
#+NAME:   fig:bench5
[[./testMExistsPerNumberOfItemsAlwaysNegative.png]]
- In every MExists test there was just one call.


As seen in the following graphs, prefix
filter is in par with the state-of-the-art filters.

Although the benchmarks don't show a clear improvement, the other
filters outperform prefix filter at most by a constant factor (and not
by an order of magnitude).

* Conclusion
- The work was mainly divided into two parts: implementing the prefix
  filter code into Redis and Compare the performance of prefix pilter
  with bloom filter and cuckoo filter
- results and conclusions: it was expected that the performance of the
  prefix filter will surpass the performance of bloom filter. However,
  we We saw that in all the indices we performed this is not the
  case. It is possible that if further improvements are made in the
  implementation, the results will be consistent with the theoy
- Learning and application: during the work We learned a lot about the
  theory and the implementation of the prefix filter, as well as
  working with redis server and RedisBloom.


\bibliographystyle{plain}
\bibliography{workshop.bib}
